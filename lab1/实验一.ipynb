{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee04865e-096f-4945-b4b0-a88dab934ddd",
   "metadata": {},
   "source": [
    "## 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64795f51-caaf-4d41-afe5-75f283e8ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09f027-741a-4d9f-af1b-03fd3dec8325",
   "metadata": {},
   "source": [
    "## 爬取电影数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab926a7-985c-4677-819a-918834d74d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0'\n",
    "}\n",
    "\n",
    "x = range(0, 125, 25)\n",
    "\n",
    "for i in x:\n",
    "    # 请求排行榜页面\n",
    "    html = requests.get(\"https://movie.douban.com/top250?start=\" + str(i), headers=headers)\n",
    "    # 防止请求过于频繁\n",
    "    time.sleep(0.01)\n",
    "    # 将获取的内容采用utf8解码\n",
    "    cont = html.content.decode('utf8')\n",
    "    # 使用正则表达式获取电影的详细页面链接\n",
    "    urlList = re.findall('<a href=\"https://movie.douban.com/subject/\\d*?/\" class=\"\">', cont)\n",
    "    # 排行榜每一页都有25个电影，于是匹配到了25个链接，逐个对访问进行请求\n",
    "    for j in range(len(urlList)):\n",
    "        # 获取标签中的url\n",
    "        url = urlList[j].replace('<a href=\"', \"\").replace('\" class=\"\">', \"\")\n",
    "        # 将获取的内容采用utf8解码\n",
    "        content = requests.get(url, headers=headers).content.decode('utf8')\n",
    "        # 采用数字作为文件名\n",
    "        print(f'i = {i}, j = {j}')\n",
    "        film_name = i + j\n",
    "        # 写入文件\n",
    "        with open('contents/' + str(film_name) + '.txt', mode='w', encoding='utf8') as f:\n",
    "            f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25db9a6-ed84-4af3-ac39-ff252c5522af",
   "metadata": {},
   "source": [
    "结点获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ee8369-3540-4946-89ca-3f2370f7dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas\n",
    "\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "def node_save(attrCont, tag, attr, label):\n",
    "    ID = []\n",
    "    for i in range(len(attrCont)):\n",
    "        ID.append(tag * 10000 + i)\n",
    "    data = {'ID': ID, attr: attrCont, 'LABEL': label}\n",
    "    dataframe = pandas.DataFrame(data)\n",
    "    dataframe.to_csv('details/' + attr + '.csv', index=False, sep=',', encoding=\"utf_8_sig\")\n",
    "\n",
    "\n",
    "def save(contents):\n",
    "    # save movie nodes\n",
    "    film_name = re.findall('<title>.*?/title>', contents)[0]\n",
    "    film_name = film_name.lstrip(\"<title>\").rstrip(\"(豆瓣)</title>\").replace(\" \", \"\")\n",
    "    film_names.append(film_name)\n",
    "\n",
    "    # save director nodes\n",
    "    director_cont = re.findall('\"director\":.*?]', contents)[0]\n",
    "    director_cont = re.findall('\"name\": \".*?\"', director_cont)\n",
    "    for i in range(len(director_cont)):\n",
    "        directors.append(director_cont[i].lstrip('\"name\": \"').rstrip('\"'))\n",
    "\n",
    "    # save actors nodes\n",
    "    actor_cont = re.findall('\"actor\":.*?]', contents)[0]\n",
    "    actor_cont = re.findall('\"name\": \".*?\"', actor_cont)\n",
    "    for i in range(len(actor_cont)):\n",
    "        actors.append(actor_cont[i].lstrip('\"name\": \"').rstrip('\"'))\n",
    "\n",
    "    # save type\n",
    "    type_cont = re.findall('<span property=\"v:genre\">.*?</span>', contents)\n",
    "    for i in range(len(type_cont)):\n",
    "        types.append(type_cont[i].lstrip('<span property=\"v:genre\">').rstrip('</span>'))\n",
    "\n",
    "\n",
    "film_names = []\n",
    "actors = []\n",
    "directors = []\n",
    "types = []\n",
    "for i in range(125):\n",
    "    with open('contents/' + str(i) + '.txt', mode='r', encoding='utf8') as f:\n",
    "        contents = f.read()\n",
    "    save(contents.replace(\"\\n\", \"\"))  # 这里需要把读出来的数据换行符去掉\n",
    "\n",
    "# 去重\n",
    "actors = list(set(actors))\n",
    "directors = list(set(directors))\n",
    "types = list(set(types))\n",
    "# 保存\n",
    "node_save(film_names, 0, 'film_name', 'movie')\n",
    "node_save(directors, 1, 'director', 'person')\n",
    "node_save(actors, 2, 'actor', 'person')\n",
    "node_save(types, 3, \"type\", \"type\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb0424-e587-4892-97ee-938edb5dc833",
   "metadata": {},
   "source": [
    "结点关系的获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a35bf2-3a67-468e-97f5-fadc7bf5dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] save acted_in finished!!!!!!!!!!!!!!!!!\n",
      "[+] save directed finished!!!!!!!!!!!!!!!!!\n",
      "[+] save belong_to finished!!!!!!!!!!!!!!!!!\n",
      "[+] save cooperation finished!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "def getID(name, nameValue):\n",
    "    df = pandas.read_csv('details/' + name + '.csv')\n",
    "    for j in range(len(df[name])):\n",
    "        if nameValue == df[name][j]:\n",
    "            return df['ID'][j]\n",
    "\n",
    "\n",
    "acted_in_data = pandas.DataFrame()\n",
    "directed_data = pandas.DataFrame()\n",
    "cooperation_data = pandas.DataFrame()\n",
    "belong_to_data = pandas.DataFrame()\n",
    "\n",
    "\n",
    "def save_relation(start_id, end_id, relation):\n",
    "    dataframe = pandas.DataFrame({':START_ID': start_id, ':END_ID': end_id, ':relation': relation, ':TYPE': relation})\n",
    "    dataframe.to_csv('details/' + relation + '.csv', index=False, sep=',', encoding=\"utf_8_sig\")\n",
    "\n",
    "\n",
    "def save_acted_in(content):\n",
    "    # 获取当前电影对应ID\n",
    "    film_name = re.findall('<title>.*?/title>', content)[0]\n",
    "    film_name = film_name.lstrip(\"<title>\").rstrip(\"(豆瓣)</title>\").replace(\" \", \"\")  # 电影名字每页只有一个\n",
    "    filmNameID = getID('film_name', film_name)\n",
    "\n",
    "    # 获取当前电影的演员和对应ID\n",
    "    actor_cont = re.findall('\"actor\":.*?]', content)[0]\n",
    "    actor_cont = re.findall('\"name\": \".*?\"', actor_cont)\n",
    "    for i in range(len(actor_cont)):  # 演员每页可能多个（通常都多个)\n",
    "        actor = actor_cont[i].lstrip('name\": \"').rstrip('\"')\n",
    "        start_id.append(filmNameID)\n",
    "        end_id.append(getID('actor', actor))  # 查找演员名字对应ID\n",
    "\n",
    "\n",
    "def save_directed(contnet):\n",
    "    # 获取当前电影对应ID\n",
    "    film_name = re.findall('<title>.*?/title>', content)[0]\n",
    "    film_name = film_name.lstrip(\"<title>\").rstrip(\"(豆瓣)</title>\").replace(\" \", \"\")\n",
    "    filmNameID = getID('film_name', film_name)\n",
    "\n",
    "    #\n",
    "    director_cont = re.findall('\"director\":.*?]', content)[0]\n",
    "    director_cont = re.findall('\"name\": \".*?\"', director_cont)\n",
    "    for i in range(len(director_cont)):\n",
    "        director = director_cont[i].lstrip('\"name\": \"').rstrip('\"')\n",
    "        start_id.append(filmNameID)\n",
    "        end_id.append(getID('director', director))\n",
    "\n",
    "\n",
    "def save_belongto(content):\n",
    "    # 获取当前电影对应ID\n",
    "    film_name = re.findall('<title>.*?/title>', content)[0]\n",
    "    film_name = film_name.lstrip(\"<title>\").rstrip(\"(豆瓣)</title>\").replace(\" \", \"\")\n",
    "    filmNameID = getID('film_name', film_name)\n",
    "\n",
    "    #\n",
    "    type_cont = re.findall('<span property=\"v:genre\">.*?</span>', content)\n",
    "    for i in range(len(type_cont)):\n",
    "        type = type_cont[i].lstrip('<span property=\"v:genre\">').rstrip('</span>')\n",
    "        start_id.append(filmNameID)\n",
    "        end_id.append(getID('type', type))\n",
    "\n",
    "\n",
    "def save_cooperation(content):\n",
    "    # 获取当前电影的演员和对应ID\n",
    "    actor_cont = re.findall('\"actor\":.*?]', content)[0]\n",
    "    actor_cont = re.findall('\"name\": \".*?\"', actor_cont)\n",
    "\n",
    "    #\n",
    "    director_cont = re.findall('\"director\":.*?]', content)[0]\n",
    "    director_cont = re.findall('\"name\": \".*?\"', director_cont)\n",
    "\n",
    "    for i in range(len(actor_cont)):\n",
    "        actor = actor_cont[i].lstrip('name\": \"').rstrip('\"')\n",
    "        for j in range(len(director_cont)):\n",
    "            director = director_cont[j].lstrip('\"name\": \"').rstrip('\"')\n",
    "            start_id.append(getID('actor', actor))\n",
    "            end_id.append(getID('director', director))\n",
    "\n",
    "\n",
    "# 用来存放关系节点ID的列表\n",
    "start_id = []\n",
    "end_id = []\n",
    "\n",
    "# 循环查找每个页面（即contents文件夹中下载下来的页面），找出对应关系(acted_in)\n",
    "for i in range(125):\n",
    "    with open('contents/' + str(i) + '.txt', mode='r', encoding='utf8') as f:\n",
    "        content = f.read().replace('\\n', \"\")  # 要去掉换行符\n",
    "    save_acted_in(content)\n",
    "save_relation(start_id, end_id, 'acted_in')\n",
    "print('[+] save acted_in finished!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "start_id.clear()\n",
    "end_id.clear()\n",
    "# 循环查找每个页面（即contents文件夹中下载下来的页面），找出对应关系(directed)\n",
    "for i in range(125):\n",
    "    with open('contents/' + str(i) + '.txt', mode='r', encoding='utf8') as f:\n",
    "        content = f.read().replace('\\n', \"\")  # 要去掉换行符\n",
    "    save_directed(content)\n",
    "save_relation(start_id, end_id, 'directed')\n",
    "print('[+] save directed finished!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "start_id.clear()\n",
    "end_id.clear()\n",
    "# 循环查找每个页面（即contents文件夹中下载下来的页面），找出对应关系(belong_to)\n",
    "for i in range(125):\n",
    "    with open('contents/' + str(i) + '.txt', mode='r', encoding='utf8') as f:\n",
    "        content = f.read().replace('\\n', \"\")  # 要去掉换行符\n",
    "    save_belongto(content)\n",
    "save_relation(start_id, end_id, 'belong_to')\n",
    "print('[+] save belong_to finished!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "start_id.clear()\n",
    "end_id.clear()\n",
    "# 循环查找每个页面（即contents文件夹中下载下来的页面），找出对应关系(cooperation)\n",
    "for i in range(125):\n",
    "    with open('contents/' + str(i) + '.txt', mode='r', encoding='utf8') as f:\n",
    "        content = f.read().replace('\\n', \"\")  # 要去掉换行符\n",
    "    save_cooperation(content)\n",
    "save_relation(start_id, end_id, 'cooperation')\n",
    "print('[+] save cooperation finished!!!!!!!!!!!!!!!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
